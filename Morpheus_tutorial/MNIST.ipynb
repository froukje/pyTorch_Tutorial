{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kwargs={'num_workers':1, 'pin_memory':True} #if GPU is used\n",
    "kwargs = {}\n",
    "train_data = torch.utils.data.DataLoader(datasets.MNIST('Data', train=True, download=True, \n",
    "                                                   transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.1307,),(0.3081,))])),\n",
    "                                    batch_size=64, shuffle=True, **kwargs)\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(datasets.MNIST('Data', train=False, \n",
    "                                                   transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.1307,),(0.3081,))])),\n",
    "                                    batch_size=64, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv_dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 60)#320  = 20*4*4 from x.size()\n",
    "        self.fc2 = nn.Linear(60, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv_dropout(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        #print(x.size())\n",
    "        #exit()\n",
    "        x = x.view(-1,320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "model = Net()\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frauke/anaconda3/envs/pytorch_base/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.21416448056697845\n",
      "Epoch: 1, Loss: 0.2612383961677551\n",
      "Epoch: 1, Loss: 0.32694971561431885\n",
      "Epoch: 1, Loss: 0.0767393708229065\n",
      "Epoch: 1, Loss: 0.19910594820976257\n",
      "Epoch: 1, Loss: 0.2513062357902527\n",
      "Epoch: 1, Loss: 0.08019469678401947\n",
      "Epoch: 1, Loss: 0.0793893113732338\n",
      "Epoch: 1, Loss: 0.22759728133678436\n",
      "Epoch: 1, Loss: 0.2822427451610565\n",
      "Epoch: 1, Loss: 0.04119652882218361\n",
      "Epoch: 1, Loss: 0.27465736865997314\n",
      "Epoch: 1, Loss: 0.14030620455741882\n",
      "Epoch: 1, Loss: 0.3135780096054077\n",
      "Epoch: 1, Loss: 0.38615813851356506\n",
      "Epoch: 1, Loss: 0.12977856397628784\n",
      "Epoch: 1, Loss: 0.20758160948753357\n",
      "Epoch: 1, Loss: 0.4247473180294037\n",
      "Epoch: 1, Loss: 0.035722922533750534\n",
      "Epoch: 1, Loss: 0.2577022612094879\n",
      "Epoch: 1, Loss: 0.13864488899707794\n",
      "Epoch: 1, Loss: 0.1515735685825348\n",
      "Epoch: 1, Loss: 0.17509813606739044\n",
      "Epoch: 1, Loss: 0.2484007030725479\n",
      "Epoch: 1, Loss: 0.528203010559082\n",
      "Epoch: 1, Loss: 0.15541259944438934\n",
      "Epoch: 1, Loss: 0.27538973093032837\n",
      "Epoch: 1, Loss: 0.22877982258796692\n",
      "Epoch: 1, Loss: 0.2847767174243927\n",
      "Epoch: 1, Loss: 0.2825295925140381\n",
      "Epoch: 1, Loss: 0.25402921438217163\n",
      "Epoch: 1, Loss: 0.24303126335144043\n",
      "Epoch: 1, Loss: 0.5086684823036194\n",
      "Epoch: 1, Loss: 0.3715614080429077\n",
      "Epoch: 1, Loss: 0.24251991510391235\n",
      "Epoch: 1, Loss: 0.5575418472290039\n",
      "Epoch: 1, Loss: 0.24590639770030975\n",
      "Epoch: 1, Loss: 0.14479130506515503\n",
      "Epoch: 1, Loss: 0.5479651093482971\n",
      "Epoch: 1, Loss: 0.11384251713752747\n",
      "Epoch: 1, Loss: 0.35086771845817566\n",
      "Epoch: 1, Loss: 0.20807944238185883\n",
      "Epoch: 1, Loss: 0.2464090883731842\n",
      "Epoch: 1, Loss: 0.2764575481414795\n",
      "Epoch: 1, Loss: 0.20901548862457275\n",
      "Epoch: 1, Loss: 0.385201632976532\n",
      "Epoch: 1, Loss: 0.210229754447937\n",
      "Epoch: 1, Loss: 0.4434993863105774\n",
      "Epoch: 1, Loss: 0.3860485553741455\n",
      "Epoch: 1, Loss: 0.2932995855808258\n",
      "Epoch: 1, Loss: 0.3246537446975708\n",
      "Epoch: 1, Loss: 0.1816074699163437\n",
      "Epoch: 1, Loss: 0.2988238036632538\n",
      "Epoch: 1, Loss: 0.257141649723053\n",
      "Epoch: 1, Loss: 0.5454885363578796\n",
      "Epoch: 1, Loss: 0.2619904577732086\n",
      "Epoch: 1, Loss: 0.1437714695930481\n",
      "Epoch: 1, Loss: 0.25274860858917236\n",
      "Epoch: 1, Loss: 0.29549872875213623\n",
      "Epoch: 1, Loss: 0.1757948249578476\n",
      "Epoch: 1, Loss: 0.35925278067588806\n",
      "Epoch: 1, Loss: 0.33317631483078003\n",
      "Epoch: 1, Loss: 0.2827521860599518\n",
      "Epoch: 1, Loss: 0.11655218154191971\n",
      "Epoch: 1, Loss: 0.42861372232437134\n",
      "Epoch: 1, Loss: 0.10705871134996414\n",
      "Epoch: 1, Loss: 0.18551164865493774\n",
      "Epoch: 1, Loss: 0.3140347898006439\n",
      "Epoch: 1, Loss: 0.06721878796815872\n",
      "Epoch: 1, Loss: 0.12370431423187256\n",
      "Epoch: 1, Loss: 0.3768690824508667\n",
      "Epoch: 1, Loss: 0.07980400323867798\n",
      "Epoch: 1, Loss: 0.13903473317623138\n",
      "Epoch: 1, Loss: 0.15043847262859344\n",
      "Epoch: 1, Loss: 0.15569333732128143\n",
      "Epoch: 1, Loss: 0.13206171989440918\n",
      "Epoch: 1, Loss: 0.38485187292099\n",
      "Epoch: 1, Loss: 0.13348238170146942\n",
      "Epoch: 1, Loss: 0.0942874401807785\n",
      "Epoch: 1, Loss: 0.20162561535835266\n",
      "Epoch: 1, Loss: 0.4258796274662018\n",
      "Epoch: 1, Loss: 0.27958551049232483\n",
      "Epoch: 1, Loss: 0.09212785959243774\n",
      "Epoch: 1, Loss: 0.07605618238449097\n",
      "Epoch: 1, Loss: 0.14084212481975555\n",
      "Epoch: 1, Loss: 0.17377135157585144\n",
      "Epoch: 1, Loss: 0.23186898231506348\n",
      "Epoch: 1, Loss: 0.19333823025226593\n",
      "Epoch: 1, Loss: 0.348258912563324\n",
      "Epoch: 1, Loss: 0.33089718222618103\n",
      "Epoch: 1, Loss: 0.08184313029050827\n",
      "Epoch: 1, Loss: 0.3049698770046234\n",
      "Epoch: 1, Loss: 0.31477439403533936\n",
      "Epoch: 1, Loss: 0.06221183016896248\n",
      "Epoch: 1, Loss: 0.32544878125190735\n",
      "Epoch: 1, Loss: 0.20295457541942596\n",
      "Epoch: 1, Loss: 0.23980647325515747\n",
      "Epoch: 1, Loss: 0.1611691415309906\n",
      "Epoch: 1, Loss: 0.24854667484760284\n",
      "Epoch: 1, Loss: 0.08530373126268387\n",
      "Epoch: 1, Loss: 0.33226320147514343\n",
      "Epoch: 1, Loss: 0.1324598789215088\n",
      "Epoch: 1, Loss: 0.14962396025657654\n",
      "Epoch: 1, Loss: 0.19356423616409302\n",
      "Epoch: 1, Loss: 0.015537109225988388\n",
      "Epoch: 1, Loss: 0.29917213320732117\n",
      "Epoch: 1, Loss: 0.16459304094314575\n",
      "Epoch: 1, Loss: 0.44901713728904724\n",
      "Epoch: 1, Loss: 0.3190171420574188\n",
      "Epoch: 1, Loss: 0.3345119059085846\n",
      "Epoch: 1, Loss: 0.6608858108520508\n",
      "Epoch: 1, Loss: 0.5868746638298035\n",
      "Epoch: 1, Loss: 0.10756360739469528\n",
      "Epoch: 1, Loss: 0.3716815114021301\n",
      "Epoch: 1, Loss: 0.3229507505893707\n",
      "Epoch: 1, Loss: 0.5819384455680847\n",
      "Epoch: 1, Loss: 0.330594539642334\n",
      "Epoch: 1, Loss: 0.19669748842716217\n",
      "Epoch: 1, Loss: 0.20501093566417694\n",
      "Epoch: 1, Loss: 0.20758368074893951\n",
      "Epoch: 1, Loss: 0.18885855376720428\n",
      "Epoch: 1, Loss: 0.32110461592674255\n",
      "Epoch: 1, Loss: 0.23679861426353455\n",
      "Epoch: 1, Loss: 0.16256050765514374\n",
      "Epoch: 1, Loss: 0.12125829607248306\n",
      "Epoch: 1, Loss: 0.22030603885650635\n",
      "Epoch: 1, Loss: 0.284330278635025\n",
      "Epoch: 1, Loss: 0.21866901218891144\n",
      "Epoch: 1, Loss: 0.7140858769416809\n",
      "Epoch: 1, Loss: 0.28885167837142944\n",
      "Epoch: 1, Loss: 0.2730461657047272\n",
      "Epoch: 1, Loss: 0.20386627316474915\n",
      "Epoch: 1, Loss: 0.15413029491901398\n",
      "Epoch: 1, Loss: 0.1822264939546585\n",
      "Epoch: 1, Loss: 0.2698419392108917\n",
      "Epoch: 1, Loss: 0.3010113835334778\n",
      "Epoch: 1, Loss: 0.17679132521152496\n",
      "Epoch: 1, Loss: 0.0794655978679657\n",
      "Epoch: 1, Loss: 0.24595974385738373\n",
      "Epoch: 1, Loss: 0.2478879988193512\n",
      "Epoch: 1, Loss: 0.07599584013223648\n",
      "Epoch: 1, Loss: 0.22568972408771515\n",
      "Epoch: 1, Loss: 0.23280039429664612\n",
      "Epoch: 1, Loss: 0.21012432873249054\n",
      "Epoch: 1, Loss: 0.12910661101341248\n",
      "Epoch: 1, Loss: 0.5178830027580261\n",
      "Epoch: 1, Loss: 0.2688605785369873\n",
      "Epoch: 1, Loss: 0.3731004297733307\n",
      "Epoch: 1, Loss: 0.39535218477249146\n",
      "Epoch: 1, Loss: 0.5119726657867432\n",
      "Epoch: 1, Loss: 0.21082966029644012\n",
      "Epoch: 1, Loss: 0.35779818892478943\n",
      "Epoch: 1, Loss: 0.34337982535362244\n",
      "Epoch: 1, Loss: 0.190322607755661\n",
      "Epoch: 1, Loss: 0.28962844610214233\n",
      "Epoch: 1, Loss: 0.15626069903373718\n",
      "Epoch: 1, Loss: 0.17683926224708557\n",
      "Epoch: 1, Loss: 0.45903897285461426\n",
      "Epoch: 1, Loss: 0.3987875282764435\n",
      "Epoch: 1, Loss: 0.21233583986759186\n",
      "Epoch: 1, Loss: 0.30082106590270996\n",
      "Epoch: 1, Loss: 0.18961094319820404\n",
      "Epoch: 1, Loss: 0.11170703172683716\n",
      "Epoch: 1, Loss: 0.7571609616279602\n",
      "Epoch: 1, Loss: 0.26001298427581787\n",
      "Epoch: 1, Loss: 0.09498283267021179\n",
      "Epoch: 1, Loss: 0.4634038507938385\n",
      "Epoch: 1, Loss: 0.36321359872817993\n",
      "Epoch: 1, Loss: 0.4750964045524597\n",
      "Epoch: 1, Loss: 0.21646815538406372\n",
      "Epoch: 1, Loss: 0.31084635853767395\n",
      "Epoch: 1, Loss: 0.31360840797424316\n",
      "Epoch: 1, Loss: 0.2986261248588562\n",
      "Epoch: 1, Loss: 0.21121080219745636\n",
      "Epoch: 1, Loss: 0.3711237609386444\n",
      "Epoch: 1, Loss: 0.23277579247951508\n",
      "Epoch: 1, Loss: 0.28135475516319275\n",
      "Epoch: 1, Loss: 0.32553553581237793\n",
      "Epoch: 1, Loss: 0.06951165944337845\n",
      "Epoch: 1, Loss: 0.12016579508781433\n",
      "Epoch: 1, Loss: 0.24548323452472687\n",
      "Epoch: 1, Loss: 0.20936989784240723\n",
      "Epoch: 1, Loss: 0.6476956605911255\n",
      "Epoch: 1, Loss: 0.21389876306056976\n",
      "Epoch: 1, Loss: 0.25535863637924194\n",
      "Epoch: 1, Loss: 0.29662585258483887\n",
      "Epoch: 1, Loss: 0.1447959691286087\n",
      "Epoch: 1, Loss: 0.13030906021595\n",
      "Epoch: 1, Loss: 0.14899247884750366\n",
      "Epoch: 1, Loss: 0.11819004267454147\n",
      "Epoch: 1, Loss: 0.36629074811935425\n",
      "Epoch: 1, Loss: 0.3828282952308655\n",
      "Epoch: 1, Loss: 0.3815717399120331\n",
      "Epoch: 1, Loss: 0.17913398146629333\n",
      "Epoch: 1, Loss: 0.27235084772109985\n",
      "Epoch: 1, Loss: 0.4764192998409271\n",
      "Epoch: 1, Loss: 0.530104398727417\n",
      "Epoch: 1, Loss: 0.1664949357509613\n",
      "Epoch: 1, Loss: 0.6106815934181213\n",
      "Epoch: 1, Loss: 0.23628763854503632\n",
      "Epoch: 1, Loss: 0.30505624413490295\n",
      "Epoch: 1, Loss: 0.4626123905181885\n",
      "Epoch: 1, Loss: 0.20997226238250732\n",
      "Epoch: 1, Loss: 0.15099813044071198\n",
      "Epoch: 1, Loss: 0.16855071485042572\n",
      "Epoch: 1, Loss: 0.28898340463638306\n",
      "Epoch: 1, Loss: 0.12094689160585403\n",
      "Epoch: 1, Loss: 0.2916942834854126\n",
      "Epoch: 1, Loss: 0.2522229552268982\n",
      "Epoch: 1, Loss: 0.4061381220817566\n",
      "Epoch: 1, Loss: 0.05766872316598892\n",
      "Epoch: 1, Loss: 0.10374528914690018\n",
      "Epoch: 1, Loss: 0.175344780087471\n",
      "Epoch: 1, Loss: 0.0776408389210701\n",
      "Epoch: 1, Loss: 0.20190107822418213\n",
      "Epoch: 1, Loss: 0.14485037326812744\n",
      "Epoch: 1, Loss: 0.13922035694122314\n",
      "Epoch: 1, Loss: 0.11546485126018524\n",
      "Epoch: 1, Loss: 0.3119261860847473\n",
      "Epoch: 1, Loss: 0.1769542396068573\n",
      "Epoch: 1, Loss: 0.2958837151527405\n",
      "Epoch: 1, Loss: 0.6977057456970215\n",
      "Epoch: 1, Loss: 0.1404503732919693\n",
      "Epoch: 1, Loss: 0.4729277491569519\n",
      "Epoch: 1, Loss: 0.09097056090831757\n",
      "Epoch: 1, Loss: 0.19299323856830597\n",
      "Epoch: 1, Loss: 0.32910001277923584\n",
      "Epoch: 1, Loss: 0.3177017867565155\n",
      "Epoch: 1, Loss: 0.3053211569786072\n",
      "Epoch: 1, Loss: 0.4121879041194916\n",
      "Epoch: 1, Loss: 0.5475412607192993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.39192718267440796\n",
      "Epoch: 1, Loss: 0.323932409286499\n",
      "Epoch: 1, Loss: 0.19612020254135132\n",
      "Epoch: 1, Loss: 0.16820287704467773\n",
      "Epoch: 1, Loss: 0.4806020259857178\n",
      "Epoch: 1, Loss: 0.15798266232013702\n",
      "Epoch: 1, Loss: 0.47336721420288086\n",
      "Epoch: 1, Loss: 0.31910181045532227\n",
      "Epoch: 1, Loss: 0.1605495661497116\n",
      "Epoch: 1, Loss: 0.5397234559059143\n",
      "Epoch: 1, Loss: 0.1630994826555252\n",
      "Epoch: 1, Loss: 0.19545598328113556\n",
      "Epoch: 1, Loss: 0.32580792903900146\n",
      "Epoch: 1, Loss: 0.2574218809604645\n",
      "Epoch: 1, Loss: 0.18486639857292175\n",
      "Epoch: 1, Loss: 0.23299168050289154\n",
      "Epoch: 1, Loss: 0.22997331619262695\n",
      "Epoch: 1, Loss: 0.11739691346883774\n",
      "Epoch: 1, Loss: 0.2679389417171478\n",
      "Epoch: 1, Loss: 0.1412871927022934\n",
      "Epoch: 1, Loss: 0.1811855137348175\n",
      "Epoch: 1, Loss: 0.19461843371391296\n",
      "Epoch: 1, Loss: 0.4623822569847107\n",
      "Epoch: 1, Loss: 0.13732776045799255\n",
      "Epoch: 1, Loss: 0.05714257061481476\n",
      "Epoch: 1, Loss: 0.12219592183828354\n",
      "Epoch: 1, Loss: 0.2307414561510086\n",
      "Epoch: 1, Loss: 0.24649019539356232\n",
      "Epoch: 1, Loss: 0.43045634031295776\n",
      "Epoch: 1, Loss: 0.21244044601917267\n",
      "Epoch: 1, Loss: 0.09993543475866318\n",
      "Epoch: 1, Loss: 0.3982775807380676\n",
      "Epoch: 1, Loss: 0.1735602468252182\n",
      "Epoch: 1, Loss: 0.5265939235687256\n",
      "Epoch: 1, Loss: 0.15885771811008453\n",
      "Epoch: 1, Loss: 0.37055039405822754\n",
      "Epoch: 1, Loss: 0.4184853434562683\n",
      "Epoch: 1, Loss: 0.3441407084465027\n",
      "Epoch: 1, Loss: 0.34714967012405396\n",
      "Epoch: 1, Loss: 0.16504420340061188\n",
      "Epoch: 1, Loss: 0.28320664167404175\n",
      "Epoch: 1, Loss: 0.26028013229370117\n",
      "Epoch: 1, Loss: 0.19083327054977417\n",
      "Epoch: 1, Loss: 0.2269255667924881\n",
      "Epoch: 1, Loss: 0.1269281804561615\n",
      "Epoch: 1, Loss: 0.6027581095695496\n",
      "Epoch: 1, Loss: 0.16782763600349426\n",
      "Epoch: 1, Loss: 0.379494845867157\n",
      "Epoch: 1, Loss: 0.3345909118652344\n",
      "Epoch: 1, Loss: 0.4392675459384918\n",
      "Epoch: 1, Loss: 0.2769332826137543\n",
      "Epoch: 1, Loss: 0.21031565964221954\n",
      "Epoch: 1, Loss: 0.4309012293815613\n",
      "Epoch: 1, Loss: 0.4319065511226654\n",
      "Epoch: 1, Loss: 0.20077557861804962\n",
      "Epoch: 1, Loss: 0.42497891187667847\n",
      "Epoch: 1, Loss: 0.2730102837085724\n",
      "Epoch: 1, Loss: 0.2581147849559784\n",
      "Epoch: 1, Loss: 0.1464032083749771\n",
      "Epoch: 1, Loss: 0.10825679451227188\n",
      "Epoch: 1, Loss: 0.18197530508041382\n",
      "Epoch: 1, Loss: 0.2852330803871155\n",
      "Epoch: 1, Loss: 0.19105327129364014\n",
      "Epoch: 1, Loss: 0.07215188443660736\n",
      "Epoch: 1, Loss: 0.13549332320690155\n",
      "Epoch: 1, Loss: 0.14766278862953186\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d3e695631464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d3e695631464>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c72bfb0b8e7d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_base/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_base/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_id, (data, target) in enumerate(train_data):\n",
    "        #data = data.cuda()\n",
    "        #target = target.cuda()\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        criterion = F.nll_loss\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch: {epoch}, Loss: {loss}')\n",
    "        \n",
    "def test():\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_data:\n",
    "        data = Variable(data)\n",
    "        #data = data.cuda()\n",
    "        target = Variable(target)\n",
    "        #target = target.cuda()\n",
    "        out = model(data)\n",
    "        loss += F.nnl_loss(out, target, size_average=False).data[0]\n",
    "        prediction = out.data.max(1,keepdim=True)[1]\n",
    "        correct += prediction.eq(target.data.view_as(prediction)).sum()\n",
    "        \n",
    "    loss = loss/len(test_data.dataset)\n",
    "    print('mean loss: {loss}')\n",
    "    print('Accuracy: {100*correct/len(test_dataset)}%')\n",
    "    \n",
    "for epoch in range(1,5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
