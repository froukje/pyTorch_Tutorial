{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class, that represents the NN\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self): #constructor; defines the variables (every layer in the NN is a variable)\n",
    "        super(MyNet, self).__init__()\n",
    "        self.lin1 = nn.Linear(10, 10) #input and output size\n",
    "        self.lin2 = nn.Linear(10, 10)\n",
    "        \n",
    "    def forward(self, x): # forward pass\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x): # needed for output \n",
    "        size = x.size()[1:] # all, except batch dimension\n",
    "        num = 1 # nr of features\n",
    "        for i in size:\n",
    "            num *= i\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (lin1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (lin2): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n",
      "MyNet(\n",
      "  (lin1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (lin2): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = MyNet()\n",
    "#net = net.cuda()\n",
    "print(net)\n",
    "if os.path.isfile('mynet.pt'):\n",
    "    net = torch.load('mynet.pt')\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2477, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2447, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2416, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2385, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2355, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2325, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2295, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2265, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2236, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2207, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2178, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2149, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2120, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2092, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2064, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2036, grad_fn=<MseLossBackward>)\n",
      "tensor(0.2008, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1981, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1953, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1926, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1900, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1873, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1847, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1820, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1795, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1769, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1744, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1718, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1693, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1669, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1644, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1620, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1596, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1572, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1549, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1525, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1502, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1479, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1435, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1391, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1369, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1348, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1326, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1306, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1285, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1264, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1244, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1224, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1205, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1185, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1166, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1147, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1128, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1110, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1091, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1073, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1055, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1038, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1021, grad_fn=<MseLossBackward>)\n",
      "tensor(0.1003, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0986, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0970, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0953, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0937, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0921, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0905, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0890, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0874, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0859, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0844, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0830, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0815, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0801, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0787, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0773, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0759, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0746, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0732, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0719, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0707, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0694, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0681, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0669, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0657, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0645, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0634, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0622, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0611, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0600, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0589, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0578, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0567, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0557, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0546, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0536, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0526, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0517, grad_fn=<MseLossBackward>)\n",
      "tensor(0.0507, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# main training loop\n",
    "#input = Variable(torch.randn(10, 10)) # input size 10, we have 10 inputs of size 10\n",
    "for i in range(100):\n",
    "    x = [1,0,0,0,1,0,0,0,1,1]\n",
    "    input = Variable(torch.Tensor([x for _ in range(10)]))\n",
    "    #input = input.cuda()\n",
    "    out = net(input)\n",
    "    #out = out.cuda()\n",
    "    #print(out) \n",
    "\n",
    "    x = [0,1,1,1,0,1,1,1,0,0]\n",
    "    target = Variable(torch.Tensor([x for _ in range(10)]))\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(out, target)\n",
    "    print(loss)\n",
    "    net.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the net\n",
    "torch.save(net, \"mynet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
